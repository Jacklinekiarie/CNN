{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOt/xArWYwjtwJePvWh0WlN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jacklinekiarie/CNN/blob/main/cat_and_dog_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all libraries"
      ],
      "metadata": {
        "id": "zLp3KVp8fDUt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoInXI5rdWH0",
        "outputId": "9bc0601b-81d1-40cb-c953-2cb54272a9ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  # This command only in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset provided batchsize and epoch. "
      ],
      "metadata": {
        "id": "lm64JHnPfKM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get project files\n",
        "#!wget https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip\n",
        "\n",
        "#!unzip cats_and_dogs.zip\n",
        "\n",
        "PATH = 'cats_and_dogs'\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "test_dir = os.path.join(PATH, 'test')\n",
        "\n",
        "# Get number of files in each directory. The train and validation directories\n",
        "# each have the subdirecories \"dogs\" and \"cats\".\n",
        "total_train = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
        "total_val = sum([len(files) for r, d, files in os.walk(validation_dir)])\n",
        "total_test = len(os.listdir(test_dir))\n",
        "\n",
        "# Variables for pre-processing and training.\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "metadata": {
        "id": "1gp06mOzdphc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an image generator. get the image used in testing and validation and testing."
      ],
      "metadata": {
        "id": "G0meWO_9fbl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0 / 255)\n",
        "validation_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0 / 255)\n",
        "test_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0 / 255)\n",
        "train_data_gen = train_image_generator.flow_from_directory(directory = train_dir,\n",
        "                                                           batch_size = batch_size,\n",
        "                                                           target_size = (IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode = \"binary\")\n",
        "val_data_gen = validation_image_generator.flow_from_directory(directory = validation_dir,\n",
        "                                                              batch_size = batch_size,\n",
        "                                                              target_size = (IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode = \"binary\")\n",
        "test_data_gen = test_image_generator.flow_from_directory(directory = PATH,\n",
        "                                                         batch_size = batch_size,\n",
        "                                                         target_size = (IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                         shuffle = False,\n",
        "                                                         classes=['test'])"
      ],
      "metadata": {
        "id": "J_3KSyB5d0nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the given images which is dog and cat in this case. "
      ],
      "metadata": {
        "id": "g_O52uABgDhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotImages(images_arr, probabilities = False):\n",
        "    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 3))\n",
        "    if probabilities is False:\n",
        "      for img, ax in zip( images_arr, axes):\n",
        "          ax.imshow(img)\n",
        "          ax.axis('off')\n",
        "    else:\n",
        "      for img, probability, ax in zip( images_arr, probabilities, axes):\n",
        "          ax.imshow(img)\n",
        "          ax.axis('off')\n",
        "          if probability > 0.5:\n",
        "              ax.set_title(\"%.2f\" % (probability*100) + \"% dog\")\n",
        "          else:\n",
        "              ax.set_title(\"%.2f\" % ((1-probability)*100) + \"% cat\")\n",
        "    plt.show()\n",
        "\n",
        "sample_training_images, _ = next(train_data_gen)\n",
        "plotImages(sample_training_images[:5])\n"
      ],
      "metadata": {
        "id": "xISxt7hid7Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Increase the number of images by rescaling, rotation zoom the image flip the image . Inorder to increase the accuracy."
      ],
      "metadata": {
        "id": "t2sMOpe-gQXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0 / 255,\n",
        "                                                                        rotation_range=40,\n",
        "                                                                        zoom_range=0.25,\n",
        "                                                                        width_shift_range=0.25,\n",
        "                                                                        height_shift_range=0.25,\n",
        "                                                                        horizontal_flip=True,\n",
        "                                                                        fill_mode='nearest')\n",
        "\n"
      ],
      "metadata": {
        "id": "AUn5ZkXBeBO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the new image generated . The out put contain 5 images different scale lighting and position . this help the model to see that image in differnt angles."
      ],
      "metadata": {
        "id": "xP5qrnllgxAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "\n",
        "plotImages(augmented_images)"
      ],
      "metadata": {
        "id": "eEqVBvdoeJS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating CNN model . It contains 3 layers. In the Input layer the conv2D has 32 filters and pixel 3x3 . Imagesize will be 200,200(imagewidht) and (imageheight).\n",
        "maxpooling shink the image into 2x2 dimension and usually 2 stride.\n",
        "walks accross the filtered image and takes the maximum number.\n",
        "Relu activation(it is a non linear function)it outputs if it is its positive and the negative number are changed to zero.\n",
        "Fully stacked cnn\n",
        "\n",
        "dense layer has 128 neuron and out put in 1 neuron."
      ],
      "metadata": {
        "id": "vKeatEuZhPNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "model = Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "               loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "F3tw0LX0eLEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train our Model"
      ],
      "metadata": {
        "id": "vDYSaZoCirc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=train_data_gen, steps_per_epoch=15, epochs=epochs, validation_data=val_data_gen, validation_steps=8, verbose=1)"
      ],
      "metadata": {
        "id": "VkUwmLc-eU_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize our output using graphs to get the  accuracy and loss of the model."
      ],
      "metadata": {
        "id": "JA6UI_7_ivcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eTcsRdCXeWE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We predict the image if it is a cat or a dog."
      ],
      "metadata": {
        "id": "T7anEyVRi-dQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "array_probabilities = model.predict(test_data_gen)\n",
        "probabilities = [i[0] for i in array_probabilities]\n",
        "\n",
        "#test_images, _ = next(test_data_gen)\n",
        "#probabilities = (model.predict(test_data_gen) >  0.5).astype(\"int32\")\n",
        "#plotImages(test_images, probabilities=probabilities)"
      ],
      "metadata": {
        "id": "1IGJ1667ebuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acurracy should atleast be 63% after training the model."
      ],
      "metadata": {
        "id": "jgPqtXlSjIre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answers =  [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
        "            1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
        "            1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
        "            1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, \n",
        "            0, 0, 0, 0, 0, 0]\n",
        "\n",
        "correct = 0\n",
        "\n",
        "for probability, answer in zip(probabilities, answers):\n",
        "  if round(probability) == answer:\n",
        "    correct +=1\n",
        "\n",
        "percentage_identified = (correct / len(answers)) * 100\n",
        "\n",
        "passed_challenge = percentage_identified >= 63\n",
        "\n",
        "print(f\"Your model correctly identified {round(percentage_identified, 2)}% of the images of cats and dogs.\")\n",
        "\n",
        "if passed_challenge:\n",
        "  print(\"You passed the challenge!\")\n",
        "else:\n",
        "  print(\"You haven't passed yet. Your model should identify at least 63% of the images. Keep trying. You will get it!\")"
      ],
      "metadata": {
        "id": "Ll5D7z-aehY0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}